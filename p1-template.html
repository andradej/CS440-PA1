
<html>
<head>
<title> CS440/640 Homework Template: HW1 Pauline Ramirez  </title>
<style>
<!--
body{
font-family: 'Trebuchet MS', Verdana;
}
p{
font-family: 'Trebuchet MS', Times;
margin: 10px 10px 15px 20px;
}
h3{
margin: 5px;
}
h2{
margin: 10px;
}
h1{
margin: 10px 0px 0px 20px;
}
div.main-body{
align:center;
margin: 30px;
}
hr{
margin:20px 0px 20px 0px;
}
-->
</style>
</head>

<body>
<center>
<a href="http://www.bu.edu"><img border="0" src="http://www.cs.bu.edu/fac/betke/images/bu-logo.gif"
width="119" height="120"></a>
</center>

<h1>Logistic Regression and Neural Networks</h1>
<p> 
 CS 440 P1 <br>
 Pauline Ramirez<br>
 Jackie Andrade<br>Joseph Cho<br>
    February 22, 2017
</p>

<div class="main-body">
<hr>
<h2> Problem Definition </h2>


<p> In this assignment, we are trying to implement both a linear regression classifier and a neural network, and then training those two classes so that they can make informed decisions based on a given input. This is useful for plenty of applications, one being image recognition. You can take a neural network, train it using already classified inputs, and then use that trained neural network to recognize other images. The difficulties really are mostly implementing the actual neural network itself, especially when it comes to having more than one hidden layer. 
<br> <br>Here are the learning objectives: <br>

<ol>
	<li>Understand how neural networks work.</li>
	<li>Implement a logistic regression classifier, and a neural network classifier.</li>
	<li>Understand the role of different parameters of a neural network, such as learning rate.</li>
	<li>Learn how to evaluate a classifier using metrics like classification accuracy and confusion matrices.</li>

</ol>


</p>

<hr>
<h2> Method and Implementation </h2>

<p>My group and I more or less just followed the skeleton code given to us, and the pseudocode that was provided on Piazza. <br><br>
For logistic regression classifier, we take in a learning rate and the dimmensions for the input and output. Using that, we were able to implement a cost computing function, and a fit function to recognize patterns from new inputs so that it can be classified based on the trained input. <br><br>
We followed the above algorithm for the neural network problem, except we accounted for the hidden layer weights and biases. We followed the backwards propagation algorithm that was taught to us in lecture.

</p>
  


<p>
	For the logistic regression classifier:

	<ul>
		<li>init: initializes the LogisticRegression class based on user input, which includes the input and output dimensions.</li>
		<li>compute_cost: computes the average cost of the data set</li>
		<li>predict: makes a prediction based on current model parameters</li>
		<li>fit: learns model parameters to fit the data.</li>
	</ul>

	<br>

	For the neural network, it's basically the same functions as above - the implementations have some variation.

</p>

<hr>
<h2>Experiments</h2>

	The first experiment was switching between linear and non linear data for the Logistic Regression Classifier. Here are the results: <br>

	<img src="images/problem1.png">

	<br><br><br>

	Here is the result using non linear data:
	<br>
	<img src="images/problem1nonlinear.png">

	<br>

	The second experiment was to change the number of nodes in the hidden layer for the Neural Network class. Here is the result of having just 2 nodes: <br>


	<img src="images/p32nodesfinal.png"> <br>

	Here is the result of having 10 nodes: <br>

	<img src="images/p310nodesfinal.png"> <br>

	<br><br><br>

	The third experiment was trying linear and nonlinear data for the neutral network using 10 nodes. The results for linear data are the same as the above image. <br>

	<img src="images/p310nodesfinal.png"> <br>

	Here are the results using nonlinear data with 10 nodes in the hidden layer: <br>

	<img src="images/p3nonlinear10nodes.png"> <br> 

	<br><br><br>

	We also experimented with training the Logistic Regression classifier to recognize digits, the confusion matrix and accuracy is shown below: <br><br>


	<img src="images/digitsLR.png"> <br>

	Here are the results using the neural network with 10 nodes in the hidden layer:<br><br>

	<img src="images/digitsNN.png"> <br> 

	

	In both cases, the accuracy was determined by running the predict function on the X_test values (given to us) to get the predicted y values. We then would compare this to the actual y_test values to get an accuracy value.


</p>


<hr>
<h2> Results</h2>


<p>
	Question 2: Can your logistic regression classifier learn non-linear decision boundaries? Why or why not? <br><br>

	No it can't because the output is determined by a linear function: output = x_input * weights + bias.

	<br><br><br>
	Question 3: Can your neural network model (with one hidden layer) learn non-linear decision boundaries? Why or why not? <br><br>

	Yes it can because the output is determined by a nonlinear activation function, which was the sigmoid function in our case. This means that our neural network is not limited to just linear data, which is the case with the linear regression classifier.

	<br><br><br>
	Question 4: What effect does learning rate have on how your neural network is trained? Illustrate your answer by training your model using different learning rates. Provide plots illustrating the total cost of your model over time for different settings of the learning rate. <br><br>

	Too high of a learning rate will cause the accuracy of the neural network to decline, which is shown below with the following image: <br>

	<img src="images/difflearningrate.png"> <br> 

	<br><br><br>
	Question 5: What effect does the number of nodes in the hidden layer have on how your neural network is trained? Illustrate your answer by training your model using different numbers of hidden layer nodes. Provide plots showing the decision boundaries learned by your model for different settings of the number of nodes in the hidden layer. <br><br>

	As we add more nodes to the hidden layer, the neural network becomes more accurate. This is shown in the image below: <br>

	<img src="images/diffnumnodes.png"> <br> 


</p>

<hr>
<h2> Discussion </h2>

<p> We are fairly satisfied with the accuracy of our neural network, which can be shown below in the case of recognizing digits:<br><br>

<img src="images/digitsNN.png"> <br> 

</p>

<hr>
<h2> Conclusions </h2>

<p>
As mentioned above, we are satisfied with the accuracy of our neural network. Our neural network is able to be trained given training data, and from that it's able to determine the class of an input, based on the patterns it has detected from the training data. 
</p>


<hr>
<h2> Credits and Bibliography </h2>


<p>Sources used:

<ul>
	<li>http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/</li>
	<li> http://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html </li>

</ul>

</p>


<hr>
</div>
</body>



</html>
