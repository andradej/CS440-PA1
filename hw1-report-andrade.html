
<html>
<head>
<title> CS440/640 Homework Template: HW1 Jackie Andrade  </title>
<style>
<!--
body{
font-family: 'Trebuchet MS', Verdana;
}
p{
font-family: 'Trebuchet MS', Times;
margin: 10px 10px 15px 20px;
}
h3{
margin: 5px;
}
h2{
margin: 10px;
}
h1{
margin: 10px 0px 0px 20px;
}
div.main-body{
align:center;
margin: 30px;
}
hr{
margin:20px 0px 20px 0px;
}
-->
</style>
</head>

<body>
<center>
<a href="http://www.bu.edu"><img border="0" src="http://www.cs.bu.edu/fac/betke/images/bu-logo.gif"
width="119" height="120"></a>
</center>

<h1>Logistic Regression and Neural Networks</h1>
<p> 
 CS 440 P1 <br>
 Jacquelyn Andrade <br>
 Team Members:
 Pauline Ramirez, Joseph Cho<br>
    February 22, 2017
</p>

<div class="main-body">
<hr>
<h2> Problem Definition </h2>


<p> In this assignment, we are trying to implement both a logistic regression classifier and a neural network classifier. We then train those two classes so that they can make informed decisions based on linear and nonlinear data inputs. <br><br>

This is useful for image recognition and machine learning. You can take a neural network, train it using already classified inputs, and then use that trained neural network to recognize other images or make a decision based on its already given data. <br><br>

The difficulty is in determining the learning rate or the number of hidden nodes in the hidden layer to put. There is a tradeoff between performance and accuracy. Another difficulty is that nonlinear is not as easy to classify since very complex data may need many hidden nodes that the class may not be able to compute efficiently.

<br> <br>Here are the learning objectives: <br>

<ol>
	<li>Understand how neural networks work.</li>
	<li>Implement a logistic regression classifier, and a neural network classifier.</li>
	<li>Understand the role of different parameters of a neural network, such as learning rate.</li>
	<li>Learn how to evaluate a classifier using metrics like classification accuracy and confusion matrices.</li>

</ol>


</p>

<hr>
<h2> Method and Implementation </h2>

<p>We followed the skeleton code given to us, and the pseudocode that was provided on Piazza. <br><br>

For <em>logistic regression classifier</em>, we take in a learning rate and the dimmensions for the input and output. We then compute the softmax scores given our input data, and find the average cost of the softmax scores to find the cost. The predict function then also computes softmax scores but makes a decision based upon which probability is highest. The predict function uses the compute cost function and backwards propogation to minimize cost and reassign weights until convergence is reached. Convergence is reached when the previous cost and current cost difference is minimal and any other further iterations will also be minimal. <br><br>

For <em>neural network classifier</em>, we take in a learning rate (epsilon), input and output dimensions, and number of hidden nodes to use for the hidden layer. In the compute_cost function we used the sigmoid function to compute softmax scores. Instead of calculating the mean score, we calculate the average loss with respect to the weights. In the predict function we once again compute the softmax scores and make a decision based on the highest loss value as this will have more effect on weights and classification in other layers. The fit function we do forward propogation (computing softmax) and backward propogation. Backward propogation consists of computing the hidden layer weight values first (error or delta3) by computing desired_output - computed_output and applying it to our sigmoid prime function. We then compute the previous layer by applying the dot product of the error (delta3) and the weights and multiplying by sigmoid prime. Given the new values computed we reassign weights nd biases.

</p>

<hr>
<h2>Experiments</h2>

	The first experiment was switching between linear and non linear data for the Logistic Regression Classifier. <br><br>

	In this first image we used linear data with 2 input dimensions, 2 output dimensions, and a learning rate of 0.01.

	<img src="images/problem1.png">

	<br><br><br>

	In the next image we used non-linear data with 2 input dimensions, 2 output dimensinos, and a learning rate of 0.01. As seen, logistic regression cannot accurately classify non-linear data as it is a linear classifier:
	<br>
	<img src="images/problem1nonlinear.png">

	<br>

	The next experiment was to change the number of nodes in the hidden layer for the Neural Network class. Here is the result of having 2 input dimensions, 2 output dimensions, learning rate of 0.01, and 2 nodes. The data is able to classify correctly, even better than the logistic regression. <br>

	<img src="images/p32nodesfinal.png"> <br>

	Here is the result of having 10 nodes. We see that the classifier tends to still predict correctly based on linear data.<br>

	<img src="images/p310nodesfinal.png"> <br>

	<br><br><br>

	The next experiment was trying nonlinear data for the neutral network using 4 nodes. Given the 2 input dimension, 2 output dimension, and 0.01 learning rate the results for non-linear are as follows. We find that our classfication does not fit the model precisely as there is some error, but is still able to predict accurately nontheless.<br>

	<img src="images/p3nonlinear2nodes.png"> <br>

	Here are the results using nonlinear data with 10 nodes in the hidden layer with the same settings as before. We find that the more hidden nodes, the better the classification, however, the longer it takes to compute.<br>

	<img src="images/p3nonlinear10nodes.png"> <br> 

	<br><br><br>

	We experimented with training the Logistic Regression classifier to recognize digits. To run these tests we ran fit function on the training data and then ran predict on our test function. We then compared our predicted values to the actual values.<br><br>

	The confusion matrix and accuracy is shown below using 2 nodes: <br><br>

	<img src="images/digitsLR.png"> <br><br>

	Here are the results using the neural network with 10 nodes in the hidden layer. Again we find that the higher the number of nodes there are, the more accurate the system is at correctly classifying, but it does take longer to compute.<br><br>

	<img src="images/digitsNN.png"> <br><br>

</p>


<hr>
<h2> Results</h2>


<p>
	<strong>Question 2:</strong> Can your logistic regression classifier learn non-linear decision boundaries? Why or why not? <br><br>

	<em>No it cannot because the prediction function for a logistic regression classifier is linear. The equation used for forwards propogation and softmax have a linear output.</em>

	<br><br>
	<strong>Question 3:</strong> Can your neural network model (with one hidden layer) learn non-linear decision boundaries? Why or why not? <br><br>

	Yes it can because the output from our model uses a nonlinear activation sigmoid function. As seen from our models in the experimentation pictures, neural networks are allowed to learn non-linear boundaries due to the non-linear nature used in our sigmoid.

	<br><br>
	<strong>Question 4:</strong> What effect does learning rate have on how your neural network is trained? Illustrate your answer by training your model using different learning rates. Provide plots illustrating the total cost of your model over time for different settings of the learning rate. <br><br>

	Too high of a learning rate will cause the accuracy of the neural network to decline. Ideally we want learning rates that are low to take bigger steps to the minimum. In the graph we notice that our trials show that lower learning rates took bigger jumps in minimizing cost as opposed to larger learning rates. In addition lower learning rates have a tendency to keep costs fairly low most of the time without fluctuation. <br><br>

	In the below graph, each line represents a different learning rate:

	<ul>
		<li>red: a learning rate of 0.01</li>
		<li>blue: a learning rate of 0.1</li>
		<li>green: a learning rate of 0.2</li>

	</ul>

	Where the x axis is the cost, and the y is time.<br>

	<img src="images/difflearningrate.png"> <br> 

	<br><br><br>
	<strong>Question 5:</strong> What effect does the number of nodes in the hidden layer have on how your neural network is trained? Illustrate your answer by training your model using different numbers of hidden layer nodes. Provide plots showing the decision boundaries learned by your model for different settings of the number of nodes in the hidden layer. <br><br>

	As we add more nodes to the hidden layer, the neural network becomes more accurate. This is shown in the image below: <br>

	As we saw in the images given in the experiments section we find that the more nodes in the hidden layer, the more accurate our system is. The system is able to easily distinguish between red and blue sections.

	In the below graph, each line represents a different amount of nodes in the hidden layer. The X axis is cost and Y is time.
	<ul>
		<li>red: 5 nodes in the hidden layer</li>
		<li>blue: 20 nodes in the hidden layer</li>
		<li>green: 40 nodes in the hidden layer</li>

	</ul>

	We notice that initially the larger the number of nodes the greater the initial cost, but it quickly decreases and the system begins to make accurate predictions as cost is quickly minimized. 

	<br>

	<img src="images/diffnumbernodes.png"> <br> 

</p>

<hr>
<h2> Discussion </h2>

<p> We are fairly satisfied with the accuracy of our neural network, as for our neural networks accuracy for digits we were able to achieve excellent accuracy.<br><br>

<img src="images/digitsNN.png"> <br> 

</p>

<hr>
<h2> Conclusions </h2>

<p>
We have determined that Logistic Regression is good on linear data but not linear data. Neural Networks seem to work better for both linear and non-linear data overall and have a superior accuracy. 
</p>


<hr>
<h2> Credits and Bibliography </h2>


<p>Sources used:

<ul>
	<li>http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/</li>
	<li> http://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html </li>

</ul>

</p>


<hr>
</div>
</body>



</html>
